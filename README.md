## About 인공지능

##### 1. 인공지능이란?
 : AI, Ai, ai는 다음 뜻을 가지고 있다.

 앵귈라(Anguilla)의 국가 코드.
어도비 일러스트레이터(Adobe Illustrator)
인공지능(artificial intelligence)
《A.I.》: 스티븐 스필버그 감독의 영화
조류 인플루엔자(avian influenza)
앰네스티 인터내셔널(Amnesty International)
에어 인디아의 IATA 호출 부호
AI : 일본에서 활동 중인 여가수
알렉사 인터넷 (Alexa Internet)

##### 2. 인공지능 분류
1. 약한(Weak) AI
특정 영역의 문제를 푸는 기술로써, '단어를 입력하면 검색 결과를 보여라', '음성을 듣고 무슨 말인지 인식하라' 같은 문제를 푸는 것

2. 강한(Strong) AI
문제의 영역을 좁혀주지 않아도 어떤 문제든 해결할 수 있는 기술 수준으로써, '터미네이터'의 '스카이넷'이나, '어벤져스2'의 '울트론'처럼 흔히 영화 속에서 볼 수 있는 로봇

현재 단계에서는 약한 AI가 많이 쓰이고 있으며, 강한 AI를 만들려면 아직 멀었다는 것이 과학계의 중론

##### 3. 인공지능과 머신러닝
![ex](http://www.epnc.co.kr/news/photo/201604/57953_55931_5931.jpg)     
약한 AI을 구현할 때는 머신러닝(기계학습)을 사용한다. 딥러닝과 머신러닝이라는 용어가 혼용되고 있지만, 머신러닝이 좀 더 큰 개념이다. 머신러닝의 방법론 중 하나가 딥러닝이다. 딥러닝은 머신러닝 방법론 중 가장 많이 쓰이는 것이기도 하다.

딥러닝 방식은 이렇다. 과거엔 데이터들을 사전지식을 동원해 분류했다. ‘귀가 뾰족하고 네 발이 보이는 사진’이라는 사전지식을 입력해 고양이 사진을 찾아내는 식이다. 이때 고양이의 귀나 다리가 사진에서 잘 안 보이면 어떻게 될까? 기계는 바로 고양이 사진이 아니라고 분류했다. 사전지식의 내용과 다르기 때문이다. 하지만 딥러닝은 이러한 사전지식을 사용하지 않는다. 일단 데이터를 넣어놓고 기계가 스스로 특성을 분류한다. 이때 무작정 데이터가 많아선 안 되며, 실제로 고양이 사진을 무엇인지 알려주는 이른바 ‘정답’ 데이터도 많아야 한다.

##### 4. 인공지능을 둘러싼 두 가지 시선
인공지능의 성능 향상에 따라 그것의 위협을 우려하는 목소리도 자연스럽게 나오고 있다. 물론 사람들이 영화를 보며 생각하는 인공지능의 수준에 미치려면 한참은 남았다는 게 전문가들의 중론이다. 그럼에도 우려의 목소리가 끊이지 않는 이유는 인공지능 발달의 파장을 가늠하기 어려워서다. 또 각 분야마다 서로 다른 방식으로 인공지능을 정의하고 개발하는 탓에 현재의 기술 수준을 파악하기조차 쉽지 않다. 인공지능 유토피아론과 디스토피아론은 이런 혼란스런 상황을 무대로 서로 엉키고 부딪힌다.

##### 5. 인공지능은 인류의 실질적인 위협일까?
세계적인 인공지능 연구자이자 구글의 엔지니어링 이사인 레이 커즈와일은 인공지능이 인류의 위협이 되지 않다고 강조하는 대표적인 인물이다. 커즈와일 이사는 인공지능의 위험을 제거할 수 있는 대안은 인류 스스로 도덕적이고 윤리적인 사회를 건설하는 것이라고 말한다. 그는 “미래에 있을지도 모를 파괴적 갈등을 피할 수 있는 최선의 방법은 폭력을 감소시켜왔던 우리 사회적 이상을 계속 진보시키는 것”이라며 “그것이 궁극적으로 인공지능을 안전하게 관리할 방법”이라고 강조했다. 커즈와일은 생물학자들이 ‘재조합 DNA’가 인류에 끼칠 위험성을 경계해 제정한 ‘아실로마 가이드라인’의 예를 들어 인공지능을 통제할 수 있다고 주장한다.

##### 6. 윤리의 테두리가 필요한 인공지능
인공지능을 반대하는 잠재적인 위험성을 가지고 있는 인공지능에 윤리적 제어가 필요하다는 목소리의 한 사례다. 인공지능의 활용 자체를 부정하는 주장은 아니다.

2015년 7월28일 아르헨티나 부에노스아이레스에서 열린 ‘국제 인공지능 컨퍼런스’에서는 인공지능 무기 군비 경쟁을 경고하는 성명서가 발표됐다. 일론 머스크 테슬라 CEO, 알파고의 아버지인 데미스 허사비스, 애플의 공동창업자 스티브 워즈니악 등 2500명이 넘는 인공지능, 로봇공학 연구가들이 인공지능 무기에 반대하는 성명서에 동참했다.

인공지능 무기는 스스로 표적을 설정하고 제거하는 무기를 말한다. 무장된 드론이 스스로 표적을 찾아 사살하는 식이다. 성명서는 “인공지능 기술이 몇 년 안에 실현 가능할 정도에 이르렀다”고 경고한다. 주요 군사국가가 인공지능 무기 개발을 시작하면 전 세계 인공지능 무기 군비 경쟁은 불가피하며, 인공지능 무기는 핵무기와 달리 비용이 비싸지도 않고 대량생산이 가능하기에 더 위험하다고 경고했다. 성명서는 인공지능 무기가 암시장에서 테러리스트들에게 거래될 수 있고, 독재자나 군부가 인종 학살에 이용할 수도 있다고 우려했다.
